消息的可靠传输、顺序，重复消费等问题在kafka中是如何解决的

消息无丢失配置，再比如消费者组rebalance过程等
主要的场景还是以消息队列的方式来应用或者说非常适合于event-driven式的上下游交互场景

1：kafka的使用以及监控和问题分析与排查？
2：听说kafka比较牛逼，它到底优秀在哪里？
3：kafka为什么这么优秀？
4：kafka和其他消息中间件相比有什么特点？
5：kafka的最佳实践？
6：老师是怎么研究kafka的？怎么像老师一样优秀？

**what?**
消息引擎系统

**how?**
*设计你的消息编码格式* 
开源的一些序列化框架，比如Google的Protocol Buffer或Facebook的Thrift 
- Kafka的选择：它使用的是纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。

*传输协议*
- 点对点模型
- 发布/订阅模型

**why?**
- 削峰填谷

**concepts**
- 发布订阅的对象是主题（Topic）
- 向主题发布消息的客户端应用程序称为生产者（Producer）
- 订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）
- Kafka的服务器端由被称为Broker的服务进程构成,负责接收和处理客户端发送过来的请求，以及对消息进行持久化
- 一个Kafka集群由多个Broker组成,更常见的做法是将不同的Broker分散运行在不同的机器上
- 把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在Kafka中被称为副本（Replica）
- 领导者副本（Leader Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。副本机制可以保证数据的持久化或消息不丢失
- 分区（Partitioning）如MongoDB和Elasticsearch中的Sharding、HBase中的Region 分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。
- 每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征
- 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的d文件
- 定期地删除消息以回收磁盘,通过日志段（Log Segment）机制
- P2P模型的方法就是引入了消费者组（Consumer Group）。所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。
- 每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）
- 消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka能够自动检测到，然后把这个Failed实例之前负责的分区转移给其他活着的消费者。这个过程就是Kafka中大名鼎鼎的“重平衡”（Rebalance）

**features**
1. 高可用
    1. 将不同的Broker分散运行在不同的机器上
    2. 备份机制（Replication）  
    3. Rebalance是Kafka消费者端实现高可用的重要手段
 2. 伸缩性 
    1. 分区（Partitioning）
 3. 高吞吐量
    1. 顺序I/O写 

**detail**

**q&a**
1. 为什么Kafka不像MySQL那样允许追随者副本对外提供读服务
Kafka 和 MySQL 是两种不同类型的系统，它们在设计和用途上有着很大的区别，这也导致了它们在支持读服务方面的不同。以下是一些导致 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务的原因：

数据模型和语义：Kafka 是一个分布式发布订阅消息系统，主要用于高吞吐量的日志数据处理和消息传递。它的主要目的是提供持久性的消息传递，而不是像 MySQL 那样提供灵活的数据存储和查询。Kafka 的消息被视为不可变的，消息一旦写入就不能修改或删除，这与 MySQL 中的可变的表数据有很大的不同。因此，Kafka 的读服务主要是针对消息流，而不是针对特定的数据行。

同步和一致性：在 MySQL 中，从节点可以通过主节点同步数据，并确保数据的一致性。然而，在 Kafka 中，消息副本之间的同步通常是异步的，并且副本之间可能会有延迟。这种异步性意味着在 Kafka 中无法保证追随者副本与主副本之间的实时一致性，因此不适合直接将追随者副本用于读服务。

可用性和性能：Kafka 的设计目标之一是提供高可用性和高吞吐量。将追随者副本用于读服务可能会增加系统的复杂性，并且可能会对性能产生影响。相比之下，Kafka 更倾向于保持简单性和可靠性，通过分区和副本机制来提高可用性，而不是通过追随者副本提供读服务。

总的来说，尽管 Kafka 和 MySQL 都是用于数据处理的系统，但它们的设计目标和用途不同，因此在支持读服务方面有着不同的实现和限制。在 Kafka 中，追随者副本通常被用于容错和故障恢复，而不是直接用于读服务。

2. 无消息丢失配置怎么实现？
配置

mq本地消息表重试
3. 多路复用是怎么回事？
4. 幂等生产者和事务生产者是一回事吗？
